{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46c53d61",
   "metadata": {},
   "source": [
    "Below section imports the required libraries for the implementation. It includes libraries like NumPy, scikit-learn (for KNN, SVM, decision trees, random forests), TensorFlow, and PyTorch for deep learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7b5a60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from torch import nn, optim\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369b0d80",
   "metadata": {},
   "source": [
    "Below section generates a synthetic dataset using the Labeled Faces in the Wild (LFW) dataset, which is available in scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1b57fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_lfw_people\n",
    "lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17397ac4",
   "metadata": {},
   "source": [
    "Split the dataset into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afbdf1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    lfw_people.data, lfw_people.target, test_size=0.25, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7b9a82",
   "metadata": {},
   "source": [
    "PCA for dimensionality reduction (Eigenfaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "794673ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 150\n",
    "pca = PCA(n_components=n_components, whiten=True).fit(X_train)\n",
    "\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6cb1b5",
   "metadata": {},
   "source": [
    "K-Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c01bd60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy: 0.6583850931677019\n"
     ]
    }
   ],
   "source": [
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_classifier.fit(X_train_pca, y_train)\n",
    "knn_predictions = knn_classifier.predict(X_test_pca)\n",
    "knn_accuracy = accuracy_score(y_test, knn_predictions)\n",
    "\n",
    "print(\"KNN Accuracy:\", knn_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add66c03",
   "metadata": {},
   "source": [
    "Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "832a57cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.7981366459627329\n"
     ]
    }
   ],
   "source": [
    "svm_classifier = SVC()\n",
    "svm_classifier.fit(X_train_pca, y_train)\n",
    "svm_predictions = svm_classifier.predict(X_test_pca)\n",
    "svm_accuracy = accuracy_score(y_test, svm_predictions)\n",
    "\n",
    "print(\"SVM Accuracy:\", svm_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170149a3",
   "metadata": {},
   "source": [
    "Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28060719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Trees Accuracy: 0.38198757763975155\n"
     ]
    }
   ],
   "source": [
    "dt_classifier = DecisionTreeClassifier()\n",
    "dt_classifier.fit(X_train_pca, y_train)\n",
    "dt_predictions = dt_classifier.predict(X_test_pca)\n",
    "dt_accuracy = accuracy_score(y_test, dt_predictions)\n",
    "print(\"Decision Trees Accuracy:\", dt_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0713ea68",
   "metadata": {},
   "source": [
    "Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d615d6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forests Accuracy: 0.5683229813664596\n"
     ]
    }
   ],
   "source": [
    "rf_classifier = RandomForestClassifier()\n",
    "rf_classifier.fit(X_train_pca, y_train)\n",
    "rf_predictions = rf_classifier.predict(X_test_pca)\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "\n",
    "print(\"Random Forests Accuracy:\", rf_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205876c7",
   "metadata": {},
   "source": [
    "Deep Learning with TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c16f7d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "13/13 [==============================] - 3s 54ms/step - loss: 1.9759 - accuracy: 0.3044 - val_loss: 1.5220 - val_accuracy: 0.4485\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 1.3561 - accuracy: 0.5220 - val_loss: 1.3172 - val_accuracy: 0.5567\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 1.0064 - accuracy: 0.6749 - val_loss: 1.1531 - val_accuracy: 0.6392\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.7566 - accuracy: 0.8148 - val_loss: 1.0299 - val_accuracy: 0.6959\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.6241 - accuracy: 0.8355 - val_loss: 0.9450 - val_accuracy: 0.7216\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.4857 - accuracy: 0.8964 - val_loss: 0.8708 - val_accuracy: 0.7371\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.3930 - accuracy: 0.9313 - val_loss: 0.8166 - val_accuracy: 0.7680\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.3232 - accuracy: 0.9469 - val_loss: 0.7717 - val_accuracy: 0.7784\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.2800 - accuracy: 0.9456 - val_loss: 0.7429 - val_accuracy: 0.7680\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.2349 - accuracy: 0.9650 - val_loss: 0.7211 - val_accuracy: 0.7835\n",
      "TensorFlow Accuracy: 0.8260869383811951\n"
     ]
    }
   ],
   "source": [
    "model_tf = keras.Sequential([\n",
    "    keras.layers.Dense(512, activation='relu', input_shape=(n_components,)),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(len(np.unique(y_train)), activation='softmax')\n",
    "])\n",
    "\n",
    "model_tf.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model_tf.fit(X_train_pca, y_train, epochs=10, batch_size=64, validation_split=0.2)\n",
    "tf_accuracy = model_tf.evaluate(X_test_pca, y_test, verbose=0)[1]\n",
    "print(\"TensorFlow Accuracy:\", tf_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8424cc61",
   "metadata": {},
   "source": [
    "Deep Learning with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77286b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(n_components, 512)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(512, len(np.unique(y_train)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model_pt = SimpleNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_pt.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885dc5ce",
   "metadata": {},
   "source": [
    "Convert numpy arrays to PyTorch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6977ccd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca_pt = torch.from_numpy(X_train_pca).float()\n",
    "y_train_pt = torch.from_numpy(y_train).long()\n",
    "X_test_pca_pt = torch.from_numpy(X_test_pca).float()\n",
    "y_test_pt = torch.from_numpy(y_test).long()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f8641d",
   "metadata": {},
   "source": [
    "Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ed14fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model_pt.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model_pt(X_train_pca_pt)\n",
    "    loss = criterion(outputs, y_train_pt)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe6b7a7",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9ed3c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Accuracy: 0.5124223602484472\n"
     ]
    }
   ],
   "source": [
    "model_pt.eval()\n",
    "with torch.no_grad():\n",
    "    pt_predictions = torch.argmax(model_pt(X_test_pca_pt), axis=1).numpy()\n",
    "    pt_accuracy = accuracy_score(y_test, pt_predictions)\n",
    "    \n",
    "    print(\"PyTorch Accuracy:\", pt_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
